"""
å¿«é€Ÿå¼€å§‹ç¤ºä¾‹ - ä½¿ç”¨ Full Self-Crawling Agent
"""

import asyncio
import os
from src.main import SelfCrawlingAgent


async def example_basic():
    """åŸºç¡€ç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ“‹ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("=" * 60)

    # 1. åˆ›å»º Agent
    api_key = os.getenv('ZHIPU_API_KEY', 'your_api_key_here')
    
    agent = SelfCrawlingAgent(
        spec_path='specs/example_ecommerce.json',
        api_key=api_key
    )

    try:
        # 2. è¿è¡Œä»»åŠ¡
        print("\nğŸš€ æ­£åœ¨è¿è¡Œçˆ¬è™«ä»»åŠ¡...")
        result = await agent.run()

        # 3. å¤„ç†ç»“æœ
        if result['success']:
            print(f"\nâœ… ä»»åŠ¡æˆåŠŸ!")
            print(f"ğŸ“Š å·²æå– {len(result['extracted_data'])} æ¡æ•°æ®")
            print(f"ğŸ“‚ è¯æ®ç›®å½•: {result['evidence_dir']}")

            # æ˜¾ç¤ºéƒ¨åˆ†æ•°æ®
            print("\nğŸ” éƒ¨åˆ†æ•°æ®é¢„è§ˆ:")
            for i, item in enumerate(result['extracted_data'][:3]):
                print(f"\n  [{i+1}] {item}")

        else:
            print(f"\nâŒ ä»»åŠ¡å¤±è´¥: {result['error']}")

    finally:
        # 4. å…³é—­
        await agent.stop()


async def example_custom():
    """è‡ªå®šä¹‰ç¤ºä¾‹ - ä½¿ç”¨è‡ªå·±çš„é…ç½®"""
    print("\n" + "=" * 60)
    print("ğŸ› ï¸  è‡ªå®šä¹‰ç¤ºä¾‹")
    print("=" * 60)

    # è‡ªå®šä¹‰ Spec é…ç½®
    custom_spec = {
        "version": "v1",
        "freeze": True,
        "created_at": "2026-02-25T12:00:00",
        "updated_at": "2026-02-25T12:00:00",
        "task_id": "custom_task_001",
        "task_name": "è‡ªå®šä¹‰ä»»åŠ¡",
        "goal": "çˆ¬å–è‡ªå®šä¹‰é¡µé¢",
        "target_url": "https://example.com",
        "max_execution_time": 300,
        "max_retries": 3,
        "max_iterations": 10,
        "targets": [
            {
                "name": "items",
                "fields": [
                    {
                        "name": "title",
                        "type": "text",
                        "selector": ".item-title",
                        "required": True
                    },
                    {
                        "name": "price",
                        "type": "number",
                        "selector": ".item-price",
                        "required": True
                    }
                ]
            }
        ],
        "completion_gate": [
            "html_snapshot_exists",
            "sense_analysis_valid",
            "execution_success"
        ],
        "evidence": {
            "required": ["spec.json", "extracted_data.json"],
            "optional": []
        },
        "capabilities": ["sense", "plan", "act", "verify"],
        "start_url": "https://example.com",
        "max_pages": 3,
        "depth_limit": 1
    }

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    import json
    with open('specs/custom_temp.json', 'w', encoding='utf-8') as f:
        json.dump(custom_spec, f, indent=2, ensure_ascii=False)

    # è¿è¡Œ
    api_key = os.getenv('ZHIPU_API_KEY', 'your_api_key_here')
    agent = SelfCrawlingAgent(
        spec_path='specs/custom_temp.json',
        api_key=api_key
    )

    try:
        result = await agent.run()

        if result['success']:
            print(f"\nâœ… è‡ªå®šä¹‰ä»»åŠ¡æˆåŠŸ!")
            print(f"ğŸ“Š å·²æå– {len(result['extracted_data'])} æ¡æ•°æ®")
        else:
            print(f"\nâŒ è‡ªå®šä¹‰ä»»åŠ¡å¤±è´¥: {result['error']}")

    finally:
        await agent.stop()


async def example_with_debug():
    """è°ƒè¯•ç¤ºä¾‹ - è·å–è¯¦ç»†ç»Ÿè®¡"""
    print("\n" + "=" * 60)
    print("ğŸ” è°ƒè¯•ç¤ºä¾‹")
    print("=" * 60)

    api_key = os.getenv('ZHIPU_API_KEY', 'your_api_key_here')
    agent = SelfCrawlingAgent(
        spec_path='specs/example_ecommerce.json',
        api_key=api_key
    )

    try:
        await agent.initialize()
        result = await agent.run()

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = agent.get_stats()

        print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
        print(f"  ğŸ“ ä»»åŠ¡ID: {stats['task_id']}")
        print(f"  ğŸ“‹ ä»»åŠ¡åç§°: {stats['task_name']}")

        if 'llm_stats' in stats:
            print(f"  ğŸ¤– LLMè°ƒç”¨æ¬¡æ•°: {stats['llm_stats'].get('call_count', 0)}")
            print(f"  ğŸ¤– LLMä½¿ç”¨Token: {stats['llm_stats'].get('total_tokens', 0)}")

        if 'cache_stats' in stats:
            print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {stats['cache_stats'].get('total_hits', 0)}")
            print(f"  ğŸ’¾ ç¼“å­˜å¤§å°: {stats['cache_stats'].get('cache_size', 0)}")

        if 'evidence_summary' in stats:
            summary = stats['evidence_summary']
            print(f"  ğŸ“¸ æˆªå›¾æ•°é‡: {summary.get('screenshots', 0)}")
            print(f"  ğŸ“„ HTMLå¿«ç…§: {summary.get('html_snapshots', 0)}")
            print(f"  ğŸ“Š æ•°æ®æ–‡ä»¶: {summary.get('data_files', 0)}")

    finally:
        await agent.stop()


if __name__ == '__main__':
    print("\n" + "=" * 60)
    print("Full Self-Crawling Agent - å¿«é€Ÿå¼€å§‹")
    print("=" * 60)

    # è¿è¡ŒåŸºç¡€ç¤ºä¾‹
    print("\n[1/3] è¿è¡ŒåŸºç¡€ç¤ºä¾‹...")
    asyncio.run(example_basic())

    # è¿è¡Œè‡ªå®šä¹‰ç¤ºä¾‹
    print("\n[2/3] è¿è¡Œè‡ªå®šä¹‰ç¤ºä¾‹...")
    asyncio.run(example_custom())

    # è¿è¡Œè°ƒè¯•ç¤ºä¾‹
    print("\n[3/3] è¿è¡Œè°ƒè¯•ç¤ºä¾‹...")
    asyncio.run(example_with_debug())

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
    print("=" * 60)

